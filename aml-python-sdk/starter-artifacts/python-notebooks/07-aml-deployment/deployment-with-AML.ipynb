{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Deployment of Automated Machine Learning Model"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Quick Start Overview\n\nIn this quickstart, you will start with a model that was trained using Automated Machine Learning. Learn how to use the Azure ML Python SDK to register, package, and deploy the trained model to Azure Container Instance as a scoring web service. Finally, test the deployed model (1) by make direct calls on service object, (2) by calling the service end point (Scoring URI) over http.\n\nBecause you will be using the Azure Machine Learning SDK, you will be able to provision all your required Azure resources directly from this notebook, without having to use the Azure Portal to create any resources."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Setup\nTo begin, you will need to provide the following information about your Azure Subscription.\n\n**If you are using your own Azure subscription, please provide names for subscription_id, resource_group, workspace_name and workspace_region to use.** Note that the workspace needs to be of type [Machine Learning Workspace](https://docs.microsoft.com/en-us/azure/machine-learning/service/setup-create-workspace).\n\n**If an environment is provided to you be sure to replace XXXXX in the values below with your unique identifier.**\n\nIn the following cell, be sure to set the values for `subscription_id`, `resource_group`, `workspace_name` and `workspace_region` as directed by the comments (*these values can be acquired from the Azure Portal*).\n\nTo get these values, do the following:\n1. Navigate to the Azure Portal and login with the credentials provided.\n2. From the left hand menu, under Favorites, select `Resource Groups`.\n3. In the list, select the resource group with the name similar to `XXXXX`.\n4. From the Overview tab, capture the desired values.\n\nExecute the following cell by selecting the `>|Run` button in the command bar above."
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "#Provide the Subscription ID of your existing Azure subscription\nsubscription_id = \"\" # <- needs to be the subscription with the Quick-Starts resource group\n\n#Provide values for the existing Resource Group \nresource_group = \"Quick-Starts-XXXXX\" # <- replace XXXXX with your unique identifier\n\n#Provide the Workspace Name and Azure Region of the Azure Machine Learning Workspace\nworkspace_name = \"quick-starts-ws-XXXXX\" # <- replace XXXXX with your unique identifier\nworkspace_region = \"eastus\" # <- region of your Quick-Starts resource group",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Download the model that was trained using Automated Machine Learning "
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "import urllib.request\nimport os\n\nmodel_folder = './automl-model'\nmodel_file_name = 'model.pkl'\nmodel_path = os.path.join(model_folder, model_file_name)\n\n# this is the URL to download a model that was trained using Automated Machine Learning \nmodel_url = ('https://quickstartsws9073123377.blob.core.windows.net/'\n             'azureml-blobstore-0d1c4218-a5f9-418b-bf55-902b65277b85/'\n             'quickstarts/automl-model/v2/model.pkl')\n\n# Download the model to your local disk in the model_folder\nos.makedirs(model_folder, exist_ok=True)\nurllib.request.urlretrieve(model_url, model_path)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Import required packages"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "The Azure Machine Learning SDK provides a comprehensive set of a capabilities that you can use directly within a notebook including:\n- Creating a **Workspace** that acts as the root object to organize all artifacts and resources used by Azure Machine Learning.\n- Creating **Experiments** in your Workspace that capture versions of the trained model along with any desired model performance telemetry. Each time you train a model and evaluate its results, you can capture that run (model and telemetry) within an Experiment.\n- Creating **Compute** resources that can be used to scale out model training, so that while your notebook may be running in a lightweight container in Azure Notebooks, your model training can actually occur on a powerful cluster that can provide large amounts of memory, CPU or GPU. \n- Using **Automated Machine Learning (AutoML)** to automatically train multiple versions of a model using a mix of different ways to prepare the data and different algorithms and hyperparameters (algorithm settings) in search of the model that performs best according to a performance metric that you specify. \n- Packaging a Docker **Image** that contains everything your trained model needs for scoring (prediction) in order to run as a web service.\n- Deploying your Image to either Azure Kubernetes or Azure Container Instances, effectively hosting the **Web Service**.\n\nIn Azure Notebooks, all of the libraries needed for Azure Machine Learning are pre-installed. To use them, you just need to import them. Run the following cell to do so:"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "import azureml.core\nfrom azureml.core import Workspace\nfrom azureml.core.webservice import Webservice, AksWebservice\nfrom azureml.core.image import Image\nfrom azureml.core.model import Model\n\nprint(\"Azure ML SDK version:\", azureml.core.VERSION)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Create and connect to an Azure Machine Learning Workspace\n\nRun the following cell to create a new Azure Machine Learning **Workspace**.\n\n**Important Note**: You will be prompted to login in the text that is output below the cell. Be sure to navigate to the URL displayed and enter the code that is provided. Once you have entered the code, return to this notebook and wait for the output to read `Workspace configuration succeeded`."
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "ws = Workspace.create(\n    name = workspace_name,\n    subscription_id = subscription_id,\n    resource_group = resource_group, \n    location = workspace_region,\n    exist_ok = True)\n\nws.write_config()\n\nprint('Workspace configuration succeeded')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Display a summary of the current environment\nimport pandas as pd\noutput = {}\noutput['SDK version'] = azureml.core.VERSION\noutput['Workspace'] = ws.name\noutput['Resource Group'] = ws.resource_group\noutput['Location'] = ws.location\npd.set_option('display.max_colwidth', -1)\npd.DataFrame(data=output, index=['']).T",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Register Model\n\nAzure Machine Learning provides a Model Registry that acts like a version controlled repository for each of your trained models. To version a model, you use  the SDK as follows. Run the following cell to register the best model with Azure Machine Learning. "
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "# register the model for deployment\nmodel = Model.register(model_path = model_path, # this points to a local file\n                       model_name = \"nyc-taxi-automl-predictor\", # name the model is registered as\n                       tags = {'area': \"auto\", 'type': \"regression\"}, \n                       description = \"NYC Taxi Fare Predictor\", \n                       workspace = ws)\n\nprint()\nprint(\"Model registered: {} \\nModel Description: {} \\nModel Version: {}\".format(model.name, \n                                                                                model.description, model.version))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Deploy the Model as a Web Service"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Create the Scoring Script\n\nAzure Machine Learning SDK gives you control over the logic of the web service, so that you can define how it retrieves the model and how the model is used for scoring. This is an important bit of flexibility. For example, you often have to prepare any input data before sending it to your model for scoring. You can define this data preparation logic (as well as the model loading approach) in the scoring file. \n\nRun the following cell to create a scoring file that will be included in the Docker Image that contains your deployed web service.\n\n**Important** Please update the `model_name` variable in the script below. The model name should be the same as the `Model registered` printed above."
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "%%writefile scoring_service.py\n\nimport json\nimport numpy as np\nimport pandas as pd\nimport azureml.train.automl\n\ncolumns = ['vendorID', 'passengerCount', 'tripDistance', 'hour_of_day', 'day_of_week', 'day_of_month', \n           'month_num', 'normalizeHolidayName', 'isPaidTimeOff', 'snowDepth', 'precipTime', \n           'precipDepth', 'temperature']\n\ndef init():\n    try:\n        # One-time initialization of predictive model and scaler\n        from azureml.core.model import Model\n        from sklearn.externals import joblib\n        global model\n        \n        model_name = 'nyc-taxi-automl-predictor'\n        print('Looking for model path for model: ', model_name)\n        model_path = Model.get_model_path(model_name=model_name)\n        print('Looking for model in: ', model_path)\n        model = joblib.load(model_path)\n        print('Model loaded...')\n\n    except Exception as e:\n        print('Exception during init: ', str(e))\n\ndef run(input_json):     \n    try:\n        inputs = json.loads(input_json)\n        data_df = pd.DataFrame(np.array(inputs).reshape(-1, len(columns)), columns = columns)\n        # Get the predictions...\n        prediction = model.predict(data_df)\n        prediction = json.dumps(prediction.tolist())\n    except Exception as e:\n        prediction = str(e)\n    return prediction",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Package Model\n\nRun the next two cells to create the deployment **Image**\n\n*WARNING: to install, build-essential needs to be available on the Docker image and is not by default. Thus, we will create a custom dockerfile with build-essential installed.*"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "%%writefile dockerfile\nRUN apt-get update && apt-get install -y build-essential",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "conda_file = 'automl_dependencies.yml'\nruntime = 'python'\n\n# create container image configuration\nprint(\"Creating container image configuration...\")\nfrom azureml.core.image import ContainerImage\nimage_config = ContainerImage.image_configuration(execution_script = 'scoring_service.py', \n                                                  runtime = runtime, \n                                                  conda_file = conda_file, \n                                                  docker_file = 'dockerfile')\n\n# create the image\nimage_name = 'nyc-taxi-automl-image'\n\nfrom azureml.core import Image\nimage = Image.create(name=image_name, models=[model], image_config=image_config, workspace=ws)\n\n# wait for image creation to finish\nimage.wait_for_creation(show_output=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Deploy Model to Azure Container Instance (ACI) as a Web Service"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "from azureml.core.webservice import AciWebservice, Webservice\n\naci_name = 'aci-cluster'\n\naci_config = AciWebservice.deploy_configuration(\n    cpu_cores = 1, \n    memory_gb = 1, \n    tags = {'name': aci_name}, \n    description = 'NYC Taxi Fare Predictor Web Service')\n\nservice_name = 'nyc-taxi-srv'\n\naci_service = Webservice.deploy_from_image(deployment_config=aci_config, \n                                           image=image, \n                                           name=service_name, \n                                           workspace=ws)\n\naci_service.wait_for_deployment(show_output=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Test the deployed web service"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Make direct calls on the service object"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "import json\n\ndata1 = [1, 2, 5, 9, 4, 27, 5, 'Memorial Day', True, 0, 0.0, 0.0, 65]\n\ndata2 = [[1, 3, 10, 15, 4, 27, 7, 'None', False, 0, 2.0, 1.0, 80], \n         [1, 2, 5, 9, 4, 27, 5, 'Memorial Day', True, 0, 0.0, 0.0, 65]]\n\nresult = aci_service.run(json.dumps(data1))\nprint('Predictions for data1')\nprint(result)\n\nresult = aci_service.run(json.dumps(data2))\nprint('Predictions for data2')\nprint(result)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Challenge Task: Consume the Deployed Web Service\n\nComplete the code below to consume the deployed webservice over HTTP\n\nA complete solution can be found in the accompanying notebook: solution-deployment-with-AML.ipynb"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "import requests\n\nurl = ...\nprint('ACI Service: {} scoring URI is: {}'.format(service_name, url))\nheaders = {'Content-Type':'application/json'}\n\n# Create request to post test data1\nresponse = ...\nprint('Predictions for data1')\nprint(response.text)\n\n# Create request to post test data2\nresponse = ...\nprint('Predictions for data2')\nprint(response.text)",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}